---
title: "final"
format: html
---

\[GitHub Repository\] (https://github.com/izzy-chang/ENVS-193DS_spring-2025_final)

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(DHARMa)
library(MuMIn)

sst <- read_csv("../data/SST_update2023.csv")
nest_boxes <- read_csv("../data/SwiftParrot_nestbox_data/occdist.csv")
```

# Problem 1. Research writing

## a. Transparent statistical methods
In part 1, they used a simple linear regression. In part 2, they used a one-way ANOVA.

## b. More information needed
1. Post-hoc comparison: The test in part 2 shows there is a difference in average nitrogen load in multiple groups (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands), but it does not specify which specific sources have higher or lower nitrogen loads. Using a post-hoc test, like Tukey's HSD, would clarify which sources contribute significantly more or less nitrogen to the San Joaquin River Delta.

2. Effect size and confidence intervals: My co-worker only mentioned p-values in their statements, but more is needed to provide context about the relationships. Reporting an effect size (correlation coefficient r in part 1, eta-squared or Cohen's d in part 2) and confidence intervals around the means or correlations would provide this valuable context.

## c. Suggestions for rewriting
Part 1: We found significant negative correlation between distance from the headwater (km) and annual total nitrogen load (kg/year) in the San Joaquin River Delta, indicatiing that nitrogen loads tend to decrease farther from the headwater (Pearson's correlation test: r = [correlation coefficient], p = 0.03, \$alpha\ = [significance level]).

Part 2: Average nitrogen load (kg/year) differed significantly among sources, suggesting that these sources vary in their contributions to nitrogen runoff (one-way ANOVA: F = [test statistic], p = 0.02, \$alpha\ = [significance level]).

**COME BACK TO THIS**

# Problem 2. Data visualization

## a. Cleaning and summarizing
```{r}
sst_clean <- sst |> 
  mutate(
    date = ymd(date),
    year = year(date),
    month = month(date, label = TRUE, abbr = TRUE)
  ) |> 
  filter(year >= 2018, year <= 2023) |> 
  group_by(year, month) |> 
  summarize(
    mean_monthly_sst = round(mean(temp, na.rm = TRUE), 1),
    .groups = "drop"
  )

slice_sample(sst_clean, n = 5)
```
```{r}
str(sst_clean)
```

## b. Visualize the data


# Problem 3. Data analysis

## a. Response variable

## b. Purpose of study

## c. Difference in "seasons"

## d. Table of models

## e. Run the models

## f. Check the diagnostics

## g. Select the best model

## h. Visualize the model predictions

## i. Write a caption for your figure

## j. Calculate model predictions

## k. Interpret your results


# Problem 4. Affective and exploratory visualizations

## a. Comparing visualizations

## b. Sharing your affective visualization
